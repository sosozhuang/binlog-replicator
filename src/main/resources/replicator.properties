canal.serverMode=kafka
canal.id=1
canal.ip=
canal.port=11111
canal.metrics.pull.port=11112
canal.zkServers=localhost:2181
canal.zookeeper.flush.period=1000
# flush meta cursor/parse position to file
canal.file.data.dir=${canal.conf.dir}
canal.file.flush.period=1000
canal.instance.memory.buffer.size=32768
canal.instance.memory.buffer.memunit=16384
canal.instance.memory.batch.mode=MEMSIZE
canal.instance.detecting.enable=true
canal.instance.detecting.sql=select 1
canal.instance.detecting.interval.time=3
canal.instance.detecting.retry.threshold=3
canal.instance.detecting.heartbeatHaEnable=true
# support maximum transaction size, more than the size of the transaction will be cut into multiple transactions delivery
canal.instance.transaction.size=2048
# mysql fallback connected to new master should fallback times
canal.instance.fallbackIntervalInSeconds=60
# network config
canal.instance.network.receiveBufferSize=32768
canal.instance.network.sendBufferSize=32768
canal.instance.network.soTimeout=30
# binlog filter config
canal.instance.filter.query.dcl=false
canal.instance.filter.query.dml=false
canal.instance.filter.query.ddl=false
canal.instance.filter.table.error=false
canal.instance.filter.rows=false
# binlog format/image check
canal.instance.binlog.format=ROW,STATEMENT,MIXED
canal.instance.binlog.image=FULL,MINIMAL,NOBLOB
# binlog ddl isolation
canal.instance.get.ddl.isolation=false
# parallel parser config
canal.instance.parser.parallel=true
## concurrent thread number, default 60% available processors, suggest not to exceed Runtime.getRuntime().availableProcessors()
canal.instance.parser.parallelThreadSize=8
## disruptor ringbuffer size, must be power of 2
canal.instance.parser.parallelBufferSize=2048
#source.destinations= example1,example2
canal.destinations=destination
# config root dir
canal.conf.dir=../conf
# auto scan instance dir add/remove and start/stop instance
canal.auto.scan=true
canal.auto.scan.interval=5
canal.instance.global.mode=spring
canal.instance.global.lazy=false
#source.instance.global.manager.address = 127.0.0.1:1099
canal.instance.global.spring.xml=classpath:spring/default-instance.xml
replicator.canal.batchSize=4096
replicator.disruptor.entry.ringBuffer.size=512
replicator.disruptor.entry.workerThreads=8
replicator.disruptor.waitStrategy=BLOCKING
# schema.table:topic,schema.table:topic
# schema.table supports regex
replicator.kafka.tableTopics=test_db1\\..*:test-topic1,test_db2\\..*:test-topic2
replicator.kafka.defaultTopic=binlog-replicator
replicator.kafka.producer.bootstrap.servers=localhost:9092
replicator.kafka.producer.compression.type=snappy
replicator.kafka.producer.acks=all
replicator.kafka.producer.retries=100
replicator.kafka.producer.max.in.flight.requests.per.connection=1
replicator.kafka.producer.enable.idempotence=false
